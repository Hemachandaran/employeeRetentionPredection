{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "725wceOTXhAU",
        "outputId": "0e8e551e-393f-4503-dc3a-0bf4d4c94ef5"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import*\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score,precision_score,recall_score,f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CL9gtqZbBOP"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv(\"aug_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "2N3vu3HfbPEK",
        "outputId": "beee410d-b818-490f-b8f1-9c9b22a2bc04"
      },
      "outputs": [],
      "source": [
        "df.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1rFg1C3bSqy",
        "outputId": "dc9c8a28-6f99-44bf-830b-d81b981894b8"
      },
      "outputs": [],
      "source": [
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZG27XJ_hrwE",
        "outputId": "b7009317-3bc4-41f6-c0b7-767dbe448404"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# creating a prerocessing funtinon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# full preprocessing in a singel function that can handle null , outliers , skewness , inbalance in data and feature engiering for categorical data \n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Preprocessing:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.imputed_df = None\n",
        "        self.balance_df = None\n",
        "        self.featureEncoded_df = None\n",
        "        self.target_mean_feature = []\n",
        "        self.categorical_features_indices = []\n",
        "\n",
        "    def handle_nulls(self):\n",
        "        \"\"\"Fill null values in specific columns.\"\"\"\n",
        "        self.df[\"enrolled_university\"] = self.df[\"enrolled_university\"].fillna(\"none\")\n",
        "        self.df[\"education_level\"] = self.df[\"education_level\"].fillna(\"Other\")\n",
        "\n",
        "        # Fill nulls in 'experience' with mode and ensure it's treated as numeric\n",
        "        mode = self.df[\"experience\"].mode()[0]\n",
        "        self.df[\"experience\"] = self.df[\"experience\"].fillna(mode)  # Ensure it's float\n",
        "\n",
        "        self.df[\"last_new_job\"] = self.df[\"last_new_job\"].fillna(\"Not Specified\")\n",
        "        self.df['major_discipline'] = self.df['major_discipline'].fillna(\"Not_Specified\")\n",
        "        self.df[\"gender\"] = self.df[\"gender\"].fillna(\"Not_specified\")\n",
        "        self.df[\"company_size\"] = self.df[\"company_size\"].fillna(\"NS\")\n",
        "        self.df[\"company_type\"] = self.df[\"company_type\"].fillna(\"not_specified\")\n",
        "        self.imputed_df = self.df\n",
        "        return self.df\n",
        "\n",
        "    def encode_features(self):\n",
        "        # Encode categorical features with target mean.\n",
        "        features = ['gender', \"enrolled_university\", \"major_discipline\",\n",
        "                    \"education_level\", \"company_type\", \"city\"]\n",
        "\n",
        "        for i, feature in enumerate(features):\n",
        "            self.target_mean_feature.append(self.df.groupby(feature)['target'].mean())\n",
        "            self.df[feature] = self.df[feature].map(self.target_mean_feature[i])\n",
        "\n",
        "        rel_exp={'Has relevent experience':1,'No relevent experience':0}\n",
        "        # Map relevant experience to binary values.\n",
        "        self.df[\"relevent_experience\"] = self.df[\"relevent_experience\"].map(rel_exp)\n",
        "\n",
        "        # Map company size categories to numerical values using map().\n",
        "        size_mapping = {'NS':1,'<10': 2,'10/49': 3,'50-99': 4,'100-500': 5,'500-999': 6,'1000-4999': 7,'5000-9999': 8,'10000+': 9}\n",
        "        self.df[\"company_size\"]=self.df[\"company_size\"].map(size_mapping)\n",
        "\n",
        "\n",
        "        # Map last new job categories to numerical values.\n",
        "\n",
        "        u=df[\"last_new_job\"].unique().tolist()\n",
        "        un=[2,6,0,5,4,3,1]\n",
        "\n",
        "        for i,j in zip(u,un):\n",
        "          self.df[\"last_new_job\"]=self.df[\"last_new_job\"].replace(i,j)\n",
        "\n",
        "\n",
        "        # Map experience categories to numerical values.\n",
        "\n",
        "        experience_mapping = {'<1': 0,'1': 1,'2': 2,'3': 3,'4': 4,\\\n",
        "                              '5': 5,'6': 6,'7': 7,'8': 8,'9': 9,\\\n",
        "                              '10': 10,'11': 11,'12': 12,'13': 13,\\\n",
        "                              '14': 14,'15': 15,'16': 16,'17': 17,\\\n",
        "                              '18': 18,'19': 19,'20': 20,'>20': 21,}\n",
        "        for i,j in zip(experience_mapping.keys(),experience_mapping.values()):\n",
        "          self.df[\"experience\"]=self.df[\"experience\"].replace(i,j)\n",
        "\n",
        "        self.featureEncoded_df = self.df\n",
        "        return self.df\n",
        "\n",
        "\n",
        "\n",
        "    def handle_outliers(self, features):\n",
        "         # Handle outliers by capping them for specified features.\n",
        "        for feature in features:\n",
        "            Q1 = self.df[feature].quantile(0.25)\n",
        "            Q3 = self.df[feature].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            \n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            \n",
        "            # Cap the outliers\n",
        "            self.df[feature] = np.where(self.df[feature] > upper_bound, upper_bound,\n",
        "                                         np.where(self.df[feature] < lower_bound, lower_bound, \n",
        "                                                  self.df[feature]))\n",
        "        \n",
        "        print(\"Outliers have been capped.\")\n",
        "        \n",
        "        return self.df   # Return the modified DataFrame\n",
        "\n",
        "    def handle_skewness(self, features):\n",
        "        \"\"\"Handle skewness using log transformation if necessary.\"\"\"\n",
        "        for feature in features:\n",
        "            skewness_value = self.df[feature].skew()\n",
        "            if skewness_value > 0.5:  \n",
        "                # Apply log transformation to reduce skewness\n",
        "                self.df[feature] = np.log(self.df[feature] + 1)  \n",
        "        \n",
        "        print(\"Skewness has been handled using log transformation where applicable.\")\n",
        "        \n",
        "        return self.df   # Return the modified DataFrame\n",
        "\n",
        "    def handle_imbalance(self):\n",
        "        \"\"\"Balance the dataset using SMOTENC.\"\"\"\n",
        "        X = self.df.drop(\"target\", axis=1)\n",
        "        y = self.df[\"target\"]\n",
        "\n",
        "        categorical_features_indices = [self.df.columns.get_loc(col) for col in['city', 'gender','relevent_experience',\\\n",
        "                                                                                'enrolled_university','education_level',\\\n",
        "                                                                                'major_discipline', 'experience',\\\n",
        "                                                                                'company_size', 'company_type',\\\n",
        "                                                                                'last_new_job']]\n",
        "\n",
        "        smote_nc = SMOTENC(categorical_features=categorical_features_indices, random_state=42)\n",
        "\n",
        "        X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
        "\n",
        "        # Concatenate the resampled data back into a DataFrame\n",
        "        self.balance_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "        # Store the balanced DataFrame back into self.df\n",
        "        self.df = self.balance_df\n",
        "        return self.balance_df\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"Run all preprocessing steps.\"\"\"       \n",
        "        \n",
        "        self.handle_nulls()\n",
        "        self.handle_imbalance()\n",
        "        self.encode_features()\n",
        "        # Handle outliers and skewness\n",
        "        self.handle_outliers(['training_hours', 'last_new_job', 'city_development_index'])\n",
        "        # self.handle_skewness(feature_list)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return self.df   # Return processed DataFrame after encoding and balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda = df.copy()\n",
        "eda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# handling null for EDA \n",
        "pre=Preprocessing(eda)\n",
        "eda = pre.handle_nulls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Gender Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='gender', hue='target', data=eda)\n",
        "plt.title('Gender Distribution by Job Change')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Education Level vs Job Change\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='education_level', hue='target', data=eda)\n",
        "plt.title('Education Level vs Job Change')\n",
        "plt.xlabel('Education Level')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Relevant Experience vs Job Change\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='relevent_experience', hue='target', data=eda)\n",
        "plt.title('Relevant Experience vs Job Change')\n",
        "plt.xlabel('Relevant Experience (0: No, 1: Yes)')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Company Size vs Job Change\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='company_size', hue='target', data=eda)\n",
        "plt.title('Company Size vs Job Change')\n",
        "plt.xlabel('Company Size')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Last New Job vs Job Change\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='last_new_job', hue='target', data=eda)\n",
        "plt.title('Last New Job vs Job Change')\n",
        "plt.xlabel('Years since Last New Job')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Major Discipline vs Job Change\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='major_discipline', hue='target', data=eda)\n",
        "plt.title('Major Discipline vs Job Change')\n",
        "plt.xlabel('Major Discipline')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Company Type vs Job Change\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='company_type', hue='target', data=eda)\n",
        "plt.title('Company Type vs Job Change')\n",
        "plt.xlabel('Company Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Job Change', loc='upper right', labels=['No', 'Yes'])\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "# Function to convert experience and last_new_job to numeric\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        if value == '>20':\n",
        "            return 21  # Assigning a value greater than 20\n",
        "        elif value == '<1':\n",
        "            return 0  # Assigning a value for less than 1 year\n",
        "        elif value == 'never':\n",
        "            return 0  # Assigning a value for never having a last new job\n",
        "        elif value.isdigit():\n",
        "            return int(value)  # Convert string digits to int\n",
        "    return np.nan  # Return NaN for any other cases\n",
        "\n",
        "# Apply conversion function to relevant columns\n",
        "eda['experience'] = eda['experience'].apply(convert_to_numeric)\n",
        "eda['last_new_job'] = eda['last_new_job'].apply(convert_to_numeric)\n",
        "\n",
        "# Function to detect outliers using IQR method and Z-score method\n",
        "def detect_outliers(EDA, feature):\n",
        "    # IQR Method\n",
        "    Q1 = eda[feature].quantile(0.25)\n",
        "    Q3 = eda[feature].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    # Identify outliers using IQR\n",
        "    outliers_iqr = eda[(eda[feature] < lower_bound) | (eda[feature] > upper_bound)]\n",
        "    \n",
        "    # Z-Score Method\n",
        "    z_scores = np.abs(stats.zscore(eda[feature].dropna()))\n",
        "    \n",
        "    # Create a boolean mask for the original DataFrame's index\n",
        "    mask = np.zeros(len(eda), dtype=bool)\n",
        "    mask[eda[feature].dropna().index] = (z_scores > 3)\n",
        "    \n",
        "    outliers_z = eda[mask]\n",
        "    \n",
        "    return outliers_iqr, outliers_z\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove the 'enrollee_id' and 'target' columns\n",
        "x = eda.drop(['enrollee_id', 'target'],axis=1)\n",
        "\n",
        "# Select numerical features\n",
        "numerical_features = x.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Melt the DataFrame to long format for seaborn\n",
        "melted_df = x[numerical_features].melt(var_name='Feature', value_name='Values')\n",
        "\n",
        "# Create a boxplot for all numerical features in a single graph\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(x='Feature', y='Values', data=melted_df)\n",
        "plt.title('Boxplots of All Numerical Features')\n",
        "plt.xticks(rotation=45)  # Rotate x labels for better readability\n",
        "plt.ylabel('Values')\n",
        "plt.xlabel('Features')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda = pre.handle_imbalance()\n",
        "eda = pre.encode_features()\n",
        "# creating box plot for all the feature \n",
        "# Select numerical features\n",
        "numerical_features = eda.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Create boxplots for each numerical feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    plt.subplot(len(numerical_features)//3 + 1, 3, i + 1)\n",
        "    plt.boxplot(eda[feature].dropna())  # Drop NaN values for plotting\n",
        "    plt.title(feature)\n",
        "    plt.ylabel('Values')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Insides of the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function in the top "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpPDBDEdSNGD"
      },
      "outputs": [],
      "source": [
        "pre_pross = Preprocessing(df)\n",
        "df=pre_pross.preprocess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# creating box plot for all the feature \n",
        "# Select numerical features\n",
        "numerical_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Create boxplots for each numerical feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    plt.subplot(len(numerical_features)//3 + 1, 3, i + 1)\n",
        "    plt.boxplot(df[feature].dropna())  # Drop NaN values for plotting\n",
        "    plt.title(feature)\n",
        "    plt.ylabel('Values')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa_4suzcO7Qk",
        "outputId": "b67585ec-66cb-4cd0-c945-87ea8ae15cbb"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oQOx9jx_GC2x"
      },
      "outputs": [],
      "source": [
        "X = df.drop(\"target\",axis=1)\n",
        "y = df[\"target\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IDXIx4-UujNh"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X =scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Kr4Lkgk3VTaw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Htvk2LcGmJV9",
        "outputId": "00b21b19-5821-4659-9453-fcfee2862300"
      },
      "outputs": [],
      "source": [
        "\"\"\"from sklearn.preprocessing import*\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score,precision_score,recall_score,f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=24),\n",
        "    \"XGBoost\": XGBClassifier(random_state=24),\n",
        "    \"LightGBM\": LGBMClassifier()\n",
        "}\n",
        "\n",
        "# Initialize a list to store metrics\n",
        "metrics_list = []\n",
        "\n",
        "# Iterate through models\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Collect metrics for training\n",
        "    metrics_train = {\n",
        "        'Model': model_name,\n",
        "        'Accuracy_Train': accuracy_score(y_train, y_train_pred),\n",
        "        'Precision_Train': precision_score(y_train, y_train_pred),\n",
        "        'Recall_Train': recall_score(y_train, y_train_pred),\n",
        "        'F1_Score_Train': f1_score(y_train, y_train_pred),\n",
        "        'AUC_ROC_Train': roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
        "    }\n",
        "\n",
        "    # Collect metrics for testing\n",
        "    metrics_test = {\n",
        "        'Accuracy_Test': accuracy_score(y_test, y_test_pred),\n",
        "        'Precision_Test': precision_score(y_test, y_test_pred),\n",
        "        'Recall_Test': recall_score(y_test, y_test_pred),\n",
        "        'F1_Score_Test': f1_score(y_test, y_test_pred),\n",
        "        'AUC_ROC_Test': roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    }\n",
        "\n",
        "    # Combine train and test metrics into one dictionary\n",
        "    combined_metrics = {**metrics_train, **metrics_test}\n",
        "\n",
        "    # Append to the list\n",
        "    metrics_list.append(combined_metrics)\n",
        "\n",
        "# Create a DataFrame from the list of metrics\n",
        "metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "# Print the DataFrame\n",
        "metrics_df\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import*\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score,precision_score,recall_score,f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "def evaluate_models(df):\n",
        "\n",
        "    #creating dependent and independent features\n",
        "    X = df.drop(\"target\",axis=1)\n",
        "    y = df[\"target\"]\n",
        "\n",
        "    # trian test split \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Define models\n",
        "    models = {\n",
        "        \"LogisticRegression\": LogisticRegression(),\n",
        "        \"RandomForestClassifier\": RandomForestClassifier(random_state=24),\n",
        "        \"XGBoost\": XGBClassifier(random_state=24),\n",
        "        \"LightGBM\": LGBMClassifier(verbosity = -1)\n",
        "    }\n",
        "\n",
        "    # Initialize a list to store metrics\n",
        "    metrics_list = []\n",
        "\n",
        "    # Iterate through models\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        # Collect metrics for training\n",
        "        metrics_train = {\n",
        "            'Model': model_name,\n",
        "            'Accuracy_Train': accuracy_score(y_train, y_train_pred),\n",
        "            'Precision_Train': precision_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "            'Recall_Train': recall_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "            'F1_Score_Train': f1_score(y_train, y_train_pred, average='weighted', zero_division=0)\n",
        "        }\n",
        "\n",
        "        # Check if the model supports ROC AUC score calculation\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            metrics_train['AUC_ROC_Train'] = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
        "        else:\n",
        "            warnings.warn(f\"{model_name} does not support probability predictions for ROC AUC.\")\n",
        "\n",
        "        # Collect metrics for testing\n",
        "        metrics_test = {\n",
        "            'Accuracy_Test': accuracy_score(y_test, y_test_pred),\n",
        "            'Precision_Test': precision_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "            'Recall_Test': recall_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "            'F1_Score_Test': f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
        "        }\n",
        "\n",
        "        # Check if the model supports ROC AUC score calculation\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            metrics_test['AUC_ROC_Test'] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "        else:\n",
        "            warnings.warn(f\"{model_name} does not support probability predictions for ROC AUC.\")\n",
        "\n",
        "        # Combine train and test metrics into one dictionary\n",
        "        combined_metrics = {**metrics_train, **metrics_test}\n",
        "\n",
        "        # Append to the list\n",
        "        metrics_list.append(combined_metrics)\n",
        "\n",
        "    # Create a DataFrame from the list of metrics\n",
        "    metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X_train, y_train, X_test, and y_test are already defined.\n",
        "# metrics_df = evaluate_models(X_train, y_train, X_test, y_test)\n",
        "# print(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_df = evaluate_models(df)\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDMwdnXSUC68"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE-CSwfZV6pM"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlrAor3V0GOn",
        "outputId": "766433fe-e24a-4345-8a51-5d7cd8a10039"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\":[200,400,600],\n",
        "    \"max_depth\":[1,2,3,4],\n",
        "    \"min_samples_split\":[2,4],\n",
        "    \"min_samples_leaf\":[2,4],\n",
        "}\n",
        "# random forest model\n",
        "rd = RandomForestClassifier()\n",
        "# grid search cv model\n",
        "grid_search = GridSearchCV(estimator=rd,param_grid=param_grid,cv=10,scoring=\"accuracy\")\n",
        "grid_search.fit(X_train,y_train) # train the model\n",
        "\n",
        "print(grid_search.best_estimator_) # print the best estimator\n",
        "print(grid_search.best_params_) # print the best parameters\n",
        "print(grid_search.best_score_) # print the best score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 200)\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 32)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
        "\n",
        "    # Create and train the Random Forest model\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and evaluate accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqr33BjEen83"
      },
      "source": [
        "#best parameter\n",
        "\n",
        "first 1:\n",
        "\n",
        "    RandomForestClassifier(max_depth=4, min_samples_leaf=4, min_samples_split=4,\n",
        "                          n_estimators=400)\n",
        "    {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 400}\n",
        "    0.8358032235511971\n",
        "\n",
        "  pass2:\n",
        "\n",
        "    RandomForestClassifier(max_depth=4, min_samples_leaf=4, min_samples_split=4,\n",
        "                          n_estimators=700)\n",
        "    {'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 700}\n",
        "    0.8359771554900517\n",
        "\n",
        "  pass3:\n",
        "\n",
        "    Best hyperparameters: {'n_estimators': 190, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 1}\n",
        "    Best accuracy: 0.8555536241960716"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97T1N-nw0GGx",
        "outputId": "9efb8f55-4ec4-4676-b000-63b538c938f9"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [300,400,500],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# XGBoost model\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Grid search CV model for XGBoost\n",
        "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_search_xgb.fit(X_train, y_train)  # Train the model\n",
        "\n",
        "print(\"Best XGBoost Estimator:\", grid_search_xgb.best_estimator_)\n",
        "print(\"Best XGBoost Parameters:\", grid_search_xgb.best_params_)\n",
        "print(\"Best XGBoost Score:\", grid_search_xgb.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
        "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
        "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
        "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
        "\n",
        "    # Create and train the XGBoost model\n",
        "    model = XGBClassifier(\n",
        "        max_depth=max_depth,\n",
        "        min_child_weight=min_child_weight,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        n_estimators=100,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and evaluate accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ah5pBMJwfPm"
      },
      "source": [
        "# best param\n",
        "\n",
        "pass1:\n",
        "\n",
        "    Best XGBoost Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
        "    Best XGBoost Score: 0.8556215553541117\n",
        "\n",
        "pass2:\n",
        "\n",
        "    Best XGBoost Parameters: {'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 1.0}\n",
        "    Best XGBoost Score: 0.8554912528227099\n",
        "\n",
        "pass3:\n",
        "    \n",
        "    Best hyperparameters: {'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.9048628638435, 'colsample_bytree': 0.5853316948275066}\n",
        "    Best accuracy: 0.8557274465496263"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhSsFOdw4z2S"
      },
      "source": [
        "# LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqYU6uHPfI8B",
        "outputId": "68d8f824-aadf-4b3e-a593-68d1edbabce0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Hyperparameter Tuning for Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.001, 0.01, 0.1,0.5,1,5,10],\n",
        "    'solver': ['lbfgs', 'liblinear','newton-cg', 'newton-cholesky']\n",
        "}\n",
        "\n",
        "# Logistic Regression model\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Grid search CV model for Logistic Regression\n",
        "grid_search_lr = GridSearchCV(estimator=lr, param_grid=param_grid_lr, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_search_lr.fit(X_train, y_train)  # Train the model\n",
        "\n",
        "print(\"Best Logistic Regression Estimator:\", grid_search_lr.best_estimator_)\n",
        "print(\"Best Logistic Regression Parameters:\", grid_search_lr.best_params_)\n",
        "print(\"Best Logistic Regression Score:\", grid_search_lr.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## best paramater \n",
        "\n",
        "pass1:\n",
        "\n",
        "        Best Logistic Regression Estimator: LogisticRegression(C=0.01, max_iter=1000, penalty='l1', solver='liblinear')\n",
        "        Best Logistic Regression Parameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
        "        Best Logistic Regression Score: 0.8295448970383307\n",
        "\n",
        "pass2:\n",
        "\n",
        "        Best Logistic Regression Estimator: LogisticRegression(C=0.5, max_iter=1000)\n",
        "        Best Logistic Regression Parameters: {'C': 0.5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
        "        Best Logistic Regression Score: 0.8291101994814157\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7O0cW8bZT1w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset (for example, using the Iris dataset)\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Check unique classes in target variable\n",
        "print(\"Unique classes in target variable:\", np.unique(y))\n",
        "\n",
        "# Stratified split to maintain class distribution\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'multiclass',  # Use 'binary' for binary classification\n",
        "        'metric': 'multi_logloss',  # Use appropriate metric for multiclass\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', -1, 50),\n",
        "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 100),\n",
        "        'lambda_l1': trial.suggest_float('lambda_l1', 0.0, 10.0),\n",
        "        'lambda_l2': trial.suggest_float('lambda_l2', 0.0, 10.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
        "    }\n",
        "\n",
        "    # Train the model\n",
        "    model = lgb.LGBMClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Validate the model\n",
        "    y_pred = model.predict(X_val)\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Create an Optuna study and optimize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50, 100],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [20, 40, 100]\n",
        "}\n",
        "\n",
        "# Create a LightGBM classifier\n",
        "lgbm = lgb.LGBMClassifier(verbosity = -1)\n",
        "\n",
        "# Set up GridSearchCV with the model and parameter grid\n",
        "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid,\n",
        "                           scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to find the best hyperparameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from GridSearchCV\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Use the best estimator to make predictions on validation set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy on validation set\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## best paramater \n",
        "\n",
        "pass1:\n",
        "\n",
        "        Best hyperparameters: {'num_leaves': 126, 'learning_rate': 0.2751701213598749, 'max_depth': 35, 'min_data_in_leaf': 10, 'lambda_l1': 7.511988202098125, 'lambda_l2': 7.412844949836307, 'bagging_fraction': 0.5954374457991968, 'feature_fraction': 0.8296990927940129}\n",
        "        Best accuracy: 0.9666666666666667\n",
        "\n",
        "pass2:\n",
        "\n",
        "        Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 20, 'num_leaves': 31}\n",
        "        Validation Accuracy: 0.9666666666666667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypermater tuning score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xjCIBs4RZTnW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "import optuna\n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def hyperparam_models(data, target_column):\n",
        "    # Split the DataFrame into features and target variable\n",
        "    X = data.drop(columns=[target_column])\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Split data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Define models and their hyperparameters for GridSearchCV\n",
        "    models = {\n",
        "        \"LogisticRegression\": {\n",
        "            \"model\": LogisticRegression(),\n",
        "            \"params\": {\n",
        "                'C': [0.001, 0.01, 0.1,0.5,1,5,10],\n",
        "                'solver': ['lbfgs', 'liblinear','newton-cg', 'newton-cholesky']\n",
        "            },\n",
        "            \"use_optuna\": False\n",
        "        },\n",
        "        \"RandomForestClassifier\": {\n",
        "            \"model\": RandomForestClassifier(random_state=24),\n",
        "            \"params\": {\n",
        "                \"max_depth\":[1,2,3,4],\n",
        "                \"min_samples_split\":[2,4],\n",
        "                \"min_samples_leaf\":[2,4],\n",
        "            },\n",
        "            \"use_optuna\": False\n",
        "        },\n",
        "        \"XGBoost\": {\n",
        "            \"model\": XGBClassifier(random_state=24),\n",
        "            \"params\": None,\n",
        "            \"use_optuna\": True\n",
        "        },\n",
        "        \"LightGBM\": {\n",
        "            \"model\": LGBMClassifier(verbosity = -1),\n",
        "            \"params\": None,\n",
        "            \"use_optuna\": True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Initialize lists to store metrics for GridSearchCV and Optuna\n",
        "    gridsearch_metrics_list = []\n",
        "    optuna_metrics_list = []\n",
        "\n",
        "    # Iterate through models\n",
        "    for model_name, model_info in models.items():\n",
        "        model = model_info[\"model\"]\n",
        "        \n",
        "        if model_info[\"use_optuna\"]:\n",
        "            # Define the objective function for Optuna\n",
        "            def objective(trial):\n",
        "                if model_name == \"XGBoost\":\n",
        "                    param = {\n",
        "                        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
        "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "                        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "                        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
        "\n",
        "                    }\n",
        "                    model.set_params(**param)\n",
        "                elif model_name == \"LightGBM\":\n",
        "                    param = {\n",
        "                        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                        'n_estimators': trial.suggest_int('n_estimators', 50, 200)\n",
        "                    }\n",
        "                    model.set_params(**param)\n",
        "\n",
        "                # Fit the model and return accuracy as the objective value\n",
        "                model.fit(X_train, y_train)\n",
        "                return accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "            # Create an Optuna study and optimize the objective function\n",
        "            study = optuna.create_study(direction='maximize')\n",
        "            study.optimize(objective, n_trials=100)\n",
        "\n",
        "            # Get best parameters from Optuna study\n",
        "            best_params = study.best_params\n",
        "            model.set_params(**best_params)\n",
        "\n",
        "            # Fit the final model with best parameters on training data\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predictions on train and test data\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for training and testing for Optuna\n",
        "            metrics = {\n",
        "                'Model': model_name,\n",
        "                'Accuracy_Train': accuracy_score(y_train, y_train_pred),\n",
        "                'Precision_Train': precision_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Train': recall_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Train': f1_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Accuracy_Test': accuracy_score(y_test, y_test_pred),\n",
        "                'Precision_Test': precision_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Test': recall_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Test': f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
        "            }\n",
        "\n",
        "            # Append metrics to the Optuna list\n",
        "            optuna_metrics_list.append(metrics)\n",
        "\n",
        "        else:\n",
        "            # Use GridSearchCV for Logistic Regression and Random Forest\n",
        "            grid_search = GridSearchCV(estimator=model,\n",
        "                                       param_grid=model_info[\"params\"],\n",
        "                                       scoring='accuracy',\n",
        "                                       cv=5,\n",
        "                                       n_jobs=-1)\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            best_params = grid_search.best_params_\n",
        "            model.set_params(**best_params)\n",
        "\n",
        "            # Fit the final model with best parameters on training data\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predictions on train and test data\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for training and testing for GridSearchCV\n",
        "            metrics = {\n",
        "                'Model': model_name,\n",
        "                'Accuracy_Train': accuracy_score(y_train, y_train_pred),\n",
        "                'Precision_Train': precision_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Train': recall_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Train': f1_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Accuracy_Test': accuracy_score(y_test, y_test_pred),\n",
        "                'Precision_Test': precision_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Test': recall_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Test': f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
        "            }\n",
        "\n",
        "            # Append metrics to the GridSearchCV list\n",
        "            gridsearch_metrics_list.append(metrics)\n",
        "\n",
        "    # Create DataFrames from the lists of metrics\n",
        "    gridsearch_metrics_df = pd.DataFrame(gridsearch_metrics_list)\n",
        "    optuna_metrics_df = pd.DataFrame(optuna_metrics_list)\n",
        "\n",
        "    return gridsearch_metrics_df, optuna_metrics_df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming data is a pandas DataFrame with a target column named 'target'.\n",
        "# metrics_gridsearch_df, metrics_optuna_df = evaluate_models(data=data_frame_with_target_column,'target')\n",
        "# print(\"GridSearchCV Results:\\n\", metrics_gridsearch_df)\n",
        "# print(\"Optuna Results:\\n\", metrics_optuna_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "import optuna\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def hyperparam_models(data, target_column):\n",
        "    # Split the DataFrame into features and target variable\n",
        "    X = data.drop(columns=[target_column])\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Split data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Define models and their hyperparameters for GridSearchCV\n",
        "    models = {\n",
        "        \"LogisticRegression\": {\n",
        "            \"model\": LogisticRegression(),\n",
        "            \"params\": {\n",
        "                'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10],\n",
        "                'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky']\n",
        "            },\n",
        "            \"use_optuna\": False\n",
        "        },\n",
        "        \"RandomForestClassifier\": {\n",
        "            \"model\": RandomForestClassifier(random_state=24),\n",
        "            \"params\": {\n",
        "                \"max_depth\": [1, 2, 3, 4],\n",
        "                \"min_samples_split\": [2, 4],\n",
        "                \"min_samples_leaf\": [2, 4],\n",
        "            },\n",
        "            \"use_optuna\": False\n",
        "        },\n",
        "        \"XGBoost\": {\n",
        "            \"model\": XGBClassifier(random_state=24),\n",
        "            \"params\": None,\n",
        "            \"use_optuna\": True\n",
        "        },\n",
        "        \"LightGBM\": {\n",
        "            \"model\": LGBMClassifier(verbosity=-1),\n",
        "            \"params\": None,\n",
        "            \"use_optuna\": True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Initialize lists to store metrics and best parameters\n",
        "    gridsearch_metrics_list = []\n",
        "    optuna_metrics_list = []\n",
        "    best_params_list = []\n",
        "\n",
        "    # Iterate through models\n",
        "    for model_name, model_info in models.items():\n",
        "        model = model_info[\"model\"]\n",
        "        \n",
        "        if model_info[\"use_optuna\"]:\n",
        "            # Define the objective function for Optuna\n",
        "            def objective(trial):\n",
        "                if model_name == \"XGBoost\":\n",
        "                    param = {\n",
        "                        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
        "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "                        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "                        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
        "                    }\n",
        "                    model.set_params(**param)\n",
        "                elif model_name == \"LightGBM\":\n",
        "                    param = {\n",
        "                        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                        'n_estimators': trial.suggest_int('n_estimators', 50, 200)\n",
        "                    }\n",
        "                    model.set_params(**param)\n",
        "\n",
        "                # Fit the model and return accuracy as the objective value\n",
        "                model.fit(X_train, y_train)\n",
        "                return accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "            # Create an Optuna study and optimize the objective function\n",
        "            study = optuna.create_study(direction='maximize')\n",
        "            study.optimize(objective, n_trials=100)\n",
        "\n",
        "            # Get best parameters from Optuna study\n",
        "            best_params = study.best_params\n",
        "            model.set_params(**best_params)\n",
        "\n",
        "            # Fit the final model with best parameters on training data\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predictions on train and test data\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for training and testing for Optuna\n",
        "            metrics = {\n",
        "                'Model': model_name,\n",
        "                'Accuracy_Train': accuracy_score(y_train, y_train_pred),\n",
        "                'Precision_Train': precision_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Train': recall_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Train': f1_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Accuracy_Test': accuracy_score(y_test, y_test_pred),\n",
        "                'Precision_Test': precision_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Test': recall_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Test': f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
        "            }\n",
        "\n",
        "            # Append metrics and best params to the lists\n",
        "            optuna_metrics_list.append(metrics)\n",
        "            best_params_list.append({'Model': model_name, 'Best_Params': best_params})\n",
        "\n",
        "        else:\n",
        "            # Use GridSearchCV for Logistic Regression and Random Forest\n",
        "            grid_search = GridSearchCV(estimator=model,\n",
        "                                       param_grid=model_info[\"params\"],\n",
        "                                       scoring='accuracy',\n",
        "                                       cv=5,\n",
        "                                       n_jobs=-1)\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            best_params = grid_search.best_params_\n",
        "            model.set_params(**best_params)\n",
        "\n",
        "            # Fit the final model with best parameters on training data\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predictions on train and test data\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            # Collect metrics for training and testing for GridSearchCV\n",
        "            metrics = {\n",
        "                'Model': model_name,\n",
        "                'Accuracy_Train': accuracy_score(y_train, y_train_pred),\n",
        "                'Precision_Train': precision_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Train': recall_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Train': f1_score(y_train, y_train_pred, average='weighted', zero_division=0),\n",
        "                'Accuracy_Test': accuracy_score(y_test, y_test_pred),\n",
        "                'Precision_Test': precision_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'Recall_Test': recall_score(y_test, y_test_pred, average='weighted', zero_division=0),\n",
        "                'F1_Score_Test': f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
        "            }\n",
        "\n",
        "            # Append metrics and best params to the lists\n",
        "            gridsearch_metrics_list.append(metrics)\n",
        "            best_params_list.append({'Model': model_name, 'Best_Params': best_params})\n",
        "\n",
        "    # Create DataFrames from the lists of metrics and parameters\n",
        "    gridsearch_metrics_df = pd.DataFrame(gridsearch_metrics_list)\n",
        "    optuna_metrics_df = pd.DataFrame(optuna_metrics_list)\n",
        "    \n",
        "    best_params_df = pd.DataFrame(best_params_list)\n",
        "\n",
        "    return gridsearch_metrics_df, optuna_metrics_df, best_params_df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming data is a pandas DataFrame with a target column named 'target'.\n",
        "# metrics_gridsearch_df, metrics_optuna_df ,best_parameters_df = hyperparam_models(data=data_frame_with_target_column,'target')\n",
        "# print(\"GridSearchCV Results:\\n\", metrics_gridsearch_df)\n",
        "# print(\"Optuna Results:\\n\", metrics_optuna_df)\n",
        "# print(\"Best Parameters:\\n\", best_parameters_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69M1g4omZTlB"
      },
      "outputs": [],
      "source": [
        "a,b,c=hyperparam_models(df,\"target\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Greadsearchcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparamater tuning score dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "h_para_score = pd.concat([a,b],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h_para_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Best paramater "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(c.Model)):\n",
        "    print(f\"{c[\"Model\"][i]}: {c[\"Best_Params\"][i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c[\"Best_Params\"][3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating the best model with the best paramater \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "params=c[\"Best_Params\"][3]\n",
        "\n",
        "model = lgb.LGBMClassifier(**params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model using joblib (pickle)\n",
        "joblib.dump(model, 'lightgbm_model.pkl')\n",
        "\n",
        "print(\"Model saved as lightgbm_model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# test based classification "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('aug_train.csv')\n",
        "\n",
        "pr = Preprocessing(data)\n",
        "data = pr.handle_nulls()\n",
        "data = pr.handle_imbalance()\n",
        "\n",
        "# Prepare the features by concatenating relevant columns into a single string\n",
        "data['combined_features'] = (\n",
        "    data['city'].fillna('') + ' ' +\n",
        "    data['gender'].fillna('') + ' ' +\n",
        "    data['relevent_experience'].fillna('') + ' ' +\n",
        "    data['enrolled_university'].fillna('') + ' ' +\n",
        "    data['education_level'].fillna('') + ' ' +\n",
        "    data['major_discipline'].fillna('') + ' ' +\n",
        "    data['experience'].fillna('') + ' ' +\n",
        "    data['company_size'].fillna('') + ' ' +\n",
        "    data['company_type'].fillna('') + ' ' +\n",
        "    data['last_new_job'].fillna('') + ' ' +\n",
        "    data['training_hours'].astype(str).fillna('')\n",
        ")\n",
        "\n",
        "# Define features and target variable\n",
        "X = data['combined_features']\n",
        "y = LabelEncoder().fit_transform(data['target'])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_tfidf)\n",
        "X_test_tensor = torch.FloatTensor(X_test_tfidf)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "y_test_tensor = torch.LongTensor(y_test)\n",
        "\n",
        "# Define the neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(64, 2)  # Output layer for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = SimpleNN(input_dim=X_train_tfidf.shape[1])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 78\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(X_train_tensor)\n",
        "\n",
        "    # Compute loss and backpropagate\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model's accuracy on the test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    _, predicted_classes = torch.max(test_outputs.data, 1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test_tensor.numpy(), predicted_classes.numpy())\n",
        "roc_auc = roc_auc_score(y_test_tensor.numpy(), torch.softmax(test_outputs, dim=1)[:, 1].numpy())\n",
        "conf_matrix = confusion_matrix(y_test_tensor.numpy(), predicted_classes.numpy())\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'ROC-AUC: {roc_auc:.2f}')\n",
        "\n",
        "# Display confusion matrix\n",
        "ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Save the model and vectorizer to disk using pickle\n",
        "with open('text_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model.state_dict(), model_file)  # Save model weights\n",
        "\n",
        "with open('vectorizer_text.pkl', 'wb') as vectorizer_file:\n",
        "    pickle.dump(vectorizer, vectorizer_file)  # Save vectorizer\n",
        "\n",
        "# Function to classify new sentences based on combined features\n",
        "def classify_features(features):\n",
        "    features_tfidf = vectorizer.transform([features]).toarray()\n",
        "    features_tensor = torch.FloatTensor(features_tfidf)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(features_tensor)\n",
        "        _, predicted_class = torch.max(output.data, 1)\n",
        "\n",
        "    return predicted_class.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing with profile summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "new_features = \"A motivated graduate with a STEM background seeking to enter the workforce. With 15 years of general experience, I am eager to apply my skills to a new role within a mid-sized private company. While I lack specific industry experience, my strong academic foundation and adaptability make me a valuable asset to any team.\"\n",
        "print(f'The features are classified as: {classify_features(new_features)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# stremlet app \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBH5_546ZTgP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFMiBe5v0F8w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class Preprocessing:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.target_mean_feature=[]\n",
        "\n",
        "    def handle_nulls(self):\n",
        "        \"\"\"Fill null values in specific columns.\"\"\"\n",
        "        self.df[\"enrolled_university\"] = self.df[\"enrolled_university\"].fillna(\"none\")\n",
        "        self.df[\"education_level\"] = self.df[\"education_level\"].fillna(\"Other\")\n",
        "        mode = self.df[\"experience\"].mode()\n",
        "        self.df[\"experience\"] = self.df[\"experience\"].fillna(mode[0])\n",
        "        self.df[\"last_new_job\"] = self.df[\"last_new_job\"].fillna(\"Not Specified\")\n",
        "        self.df['major_discipline'] = self.df['major_discipline'].fillna(\"Not Specified\")\n",
        "        self.df[\"gender\"] = self.df[\"gender\"].fillna(\"Not Specified\")\n",
        "        self.df[\"company_size\"] = self.df[\"company_size\"].fillna(\"Not Specified\")\n",
        "        self.df[\"company_type\"] = self.df[\"company_type\"].fillna(\"Not Specified\")\n",
        "\n",
        "    def encode_features(self):\n",
        "        \"\"\"Encode categorical features with target mean.\"\"\"\n",
        "        features = ['gender', \"enrolled_university\", \"major_discipline\",\n",
        "                    \"education_level\", \"company_type\", \"city\"]\n",
        "\n",
        "        for i,feature in enumerate(features):\n",
        "            self.target_mean_feature.append(self.df.groupby(feature)['target'].mean())\n",
        "            self.df[feature] = self.df[feature].map(target_mean_feature[i])\n",
        "\n",
        "        \"\"\"Map relevant experience to binary values.\"\"\"\n",
        "        self.df[\"relevent_experience\"] = self.df[\"relevent_experience\"].map({\n",
        "            'Has relevent experience': 1,\n",
        "            'No relevent experience': 0\n",
        "        })\n",
        "\n",
        "        \"\"\"Map company size categories to numerical values.\"\"\"\n",
        "        size_mapping = {\n",
        "            'Not Specified': 1,\n",
        "            '<10': 2,\n",
        "            '10/49': 3,\n",
        "            '50-99': 4,\n",
        "            '100-500': 5,\n",
        "            '500-999': 6,\n",
        "            '1000-4999': 7,\n",
        "            '5000-9999': 8,\n",
        "            '10000+': 9\n",
        "        }\n",
        "\n",
        "        self.df[\"company_size\"] = self.df[\"company_size\"].replace(size_mapping)\n",
        "\n",
        "        \"\"\"Map last new job categories to numerical values.\"\"\"\n",
        "        last_new_job_mapping = {\n",
        "            'Not Specified': 0,\n",
        "            '<1': 1,\n",
        "            '1': 2,\n",
        "            '2': 3,\n",
        "            '3': 4,\n",
        "            '4': 5,\n",
        "            '5': 6,\n",
        "            '6': 7,\n",
        "            '7': 8,\n",
        "            '8': 9,\n",
        "            '9': 10,\n",
        "            '10': 11,\n",
        "            '11': 12,\n",
        "            '12': 13,\n",
        "            '13': 14,\n",
        "            '14': 15,\n",
        "            '15': 16,\n",
        "            '16': 17,\n",
        "            '17': 18,\n",
        "            '18': 19,\n",
        "            '19': 20,\n",
        "            '>20': 21\n",
        "        }\n",
        "\n",
        "        unique_jobs = sorted(self.df[\"last_new_job\"].unique().tolist())\n",
        "\n",
        "        # Map last new job based on unique values\n",
        "        for i in unique_jobs:\n",
        "            if i in last_new_job_mapping:\n",
        "                self.df[\"last_new_job\"] = self.df[\"last_new_job\"].replace(i, last_new_job_mapping[i])\n",
        "\n",
        "        \"\"\"Map experience categories to numerical values.\"\"\"\n",
        "        experience_mapping = {\n",
        "            '>20': 21,\n",
        "            '<1': 0,\n",
        "            '1': 1,\n",
        "            '2': 2,\n",
        "            '3': 3,\n",
        "            '4': 4,\n",
        "            '5': 5,\n",
        "            '6': 6,\n",
        "            '7': 7,\n",
        "            '8': 8,\n",
        "            '9': 9,\n",
        "            '10': 10,\n",
        "            '11': 11,\n",
        "            '12': 12,\n",
        "            '13': 13,\n",
        "            '14': 14,\n",
        "            '15': 15,\n",
        "            '16': 16,\n",
        "            '17': 17,\n",
        "            '18': 18,\n",
        "            '19': 19,\n",
        "            '20': 20\n",
        "        }\n",
        "\n",
        "        self.df[\"experience\"] = self.df[\"experience\"].map(experience_mapping)\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"Run all preprocessing steps.\"\"\"\n",
        "        self.handle_nulls()\n",
        "        self.encode_features()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "# preprocessor = Preprocessing(df)\n",
        "# preprocessor.preprocess()\n",
        "# processed_df = preprocessor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeZ7vcFY0F6y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLiLHYbp0F4f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5r2ZqgL7i7o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV4n4_il7i5e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93gnMA127i3o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvj4JOlQ7i1s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI7_U1jg7izL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E57I3q_07ixC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "class Preprocessing:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.target_mean_feature=[]\n",
        "\n",
        "    def handle_nulls(self):\n",
        "        \"\"\"Fill null values in specific columns.\"\"\"\n",
        "        self.df[\"enrolled_university\"] = self.df[\"enrolled_university\"].fillna(\"none\")\n",
        "        self.df[\"education_level\"] = self.df[\"education_level\"].fillna(\"Other\")\n",
        "        mode = self.df[\"experience\"].mode()\n",
        "        self.df[\"experience\"] = self.df[\"experience\"].fillna(mode[0])\n",
        "        self.df[\"last_new_job\"] = self.df[\"last_new_job\"].fillna(\"Not Specified\")\n",
        "        self.df['major_discipline'] = self.df['major_discipline'].fillna(\"Not Specified\")\n",
        "        self.df[\"gender\"] = self.df[\"gender\"].fillna(\"Not Specified\")\n",
        "        self.df[\"company_size\"] = self.df[\"company_size\"].fillna(\"Not Specified\")\n",
        "        self.df[\"company_type\"] = self.df[\"company_type\"].fillna(\"Not Specified\")\n",
        "\n",
        "    def encode_features(self):\n",
        "        \"\"\"Encode categorical features with target mean.\"\"\"\n",
        "        features = ['gender', \"enrolled_university\", \"major_discipline\",\n",
        "                    \"education_level\", \"company_type\", \"city\"]\n",
        "\n",
        "        for i,feature in enumerate(features):\n",
        "            self.target_mean_feature.append(self.df.groupby(feature)['target'].mean())\n",
        "            self.df[feature] = self.df[feature].map(target_mean_feature[i])\n",
        "\n",
        "        \"\"\"Map relevant experience to binary values.\"\"\"\n",
        "        self.df[\"relevent_experience\"] = self.df[\"relevent_experience\"].map({\n",
        "            'Has relevent experience': 1,\n",
        "            'No relevent experience': 0\n",
        "        })\n",
        "\n",
        "        \"\"\"Map company size categories to numerical values.\"\"\"\n",
        "        size_mapping = {\n",
        "            'Not Specified': 1,\n",
        "            '<10': 2,\n",
        "            '10/49': 3,\n",
        "            '50-99': 4,\n",
        "            '100-500': 5,\n",
        "            '500-999': 6,\n",
        "            '1000-4999': 7,\n",
        "            '5000-9999': 8,\n",
        "            '10000+': 9\n",
        "        }\n",
        "\n",
        "        self.df[\"company_size\"] = self.df[\"company_size\"].replace(size_mapping)\n",
        "\n",
        "        \"\"\"Map last new job categories to numerical values.\"\"\"\n",
        "        last_new_job_mapping = {\n",
        "            'Not Specified': 0,\n",
        "            '<1': 1,\n",
        "            '1': 2,\n",
        "            '2': 3,\n",
        "            '3': 4,\n",
        "            '4': 5,\n",
        "            '5': 6,\n",
        "            '6': 7,\n",
        "            '7': 8,\n",
        "            '8': 9,\n",
        "            '9': 10,\n",
        "            '10': 11,\n",
        "            '11': 12,\n",
        "            '12': 13,\n",
        "            '13': 14,\n",
        "            '14': 15,\n",
        "            '15': 16,\n",
        "            '16': 17,\n",
        "            '17': 18,\n",
        "            '18': 19,\n",
        "            '19': 20,\n",
        "            '>20': 21\n",
        "        }\n",
        "\n",
        "        unique_jobs = sorted(self.df[\"last_new_job\"].unique().tolist())\n",
        "\n",
        "        # Map last new job based on unique values\n",
        "        for i in unique_jobs:\n",
        "            if i in last_new_job_mapping:\n",
        "                self.df[\"last_new_job\"] = self.df[\"last_new_job\"].replace(i, last_new_job_mapping[i])\n",
        "\n",
        "        \"\"\"Map experience categories to numerical values.\"\"\"\n",
        "        experience_mapping = {\n",
        "            '>20': 21,\n",
        "            '<1': 0,\n",
        "            '1': 1,\n",
        "            '2': 2,\n",
        "            '3': 3,\n",
        "            '4': 4,\n",
        "            '5': 5,\n",
        "            '6': 6,\n",
        "            '7': 7,\n",
        "            '8': 8,\n",
        "            '9': 9,\n",
        "            '10': 10,\n",
        "            '11': 11,\n",
        "            '12': 12,\n",
        "            '13': 13,\n",
        "            '14': 14,\n",
        "            '15': 15,\n",
        "            '16': 16,\n",
        "            '17': 17,\n",
        "            '18': 18,\n",
        "            '19': 19,\n",
        "            '20': 20\n",
        "        }\n",
        "\n",
        "        self.df[\"experience\"] = self.df[\"experience\"].map(experience_mapping)\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"Run all preprocessing steps.\"\"\"\n",
        "        self.handle_nulls()\n",
        "        self.encode_features()\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "# preprocessor = Preprocessing(df)\n",
        "# preprocessor.preprocess()\n",
        "# processed_df = preprocessor.df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
